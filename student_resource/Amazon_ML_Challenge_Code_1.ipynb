{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eOKMwk8zgzXE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nZUilvILg-O4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39efe1d9-3572-4588-96c2-14238ca2c491"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/drive/My Drive/ML_Hackathon/68e8d1d70b66d_student_resource.zip'"
      ],
      "metadata": {
        "id": "WiTnaUgfhAnn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_path = '/content/'"
      ],
      "metadata": {
        "id": "-lqXdvv4hSbf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_path)\n",
        "\n",
        "print(\"Files have been unzipped successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWyoEEjahU5A",
        "outputId": "ca0e17e2-4b19-4e71-eee3-11a7208b642f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files have been unzipped successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Base path to your data, based on the unzipped folder structure\n",
        "base_path = '/content/68e8d1d70b66d_student_resource/student_resource'"
      ],
      "metadata": {
        "id": "GhmzRBPjhXFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/student_resource/dataset/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/student_resource/dataset/test.csv\")"
      ],
      "metadata": {
        "id": "FFO7wJB_h_Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "e6xLkJPTiJat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "v54ZABHLjLUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "OzSlnCBmjVoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"catalog_content\"][0]"
      ],
      "metadata": {
        "id": "Vnf2D56zjmEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.info()"
      ],
      "metadata": {
        "id": "hyWGt3OIjta4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "e9FGFu_Oj3p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot a histogram of the price\n",
        "sns.histplot(train_df['price'], bins=50, kde=True, ax=axes[0])\n",
        "axes[0].set_title('Distribution of Product Prices (Histogram)')\n",
        "axes[0].set_xlabel('Price')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "# Plot a box plot of the price to spot outliers\n",
        "sns.boxplot(x=train_df['price'], ax=axes[1])\n",
        "axes[1].set_title('Distribution of Product Prices (Box Plot)')\n",
        "axes[1].set_xlabel('Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NOZrGxkRkHqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['word_count'] = train_df['catalog_content'].str.split().str.len()"
      ],
      "metadata": {
        "id": "Y5ao-cJBkLSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(train_df['word_count'], bins=50, kde=True)\n",
        "plt.title('Distribution of Word Count in catalog_content')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FMjrMTIAkzn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"word_count\"].describe()"
      ],
      "metadata": {
        "id": "a7LdNN6Ek2_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "all_words = ' '.join(train_df['catalog_content'].fillna('')).split()\n",
        "most_common_words = Counter(all_words).most_common(20)\n",
        "\n",
        "print(\"\\n--- Most Common Words in catalog_content ---\")\n",
        "print(most_common_words)"
      ],
      "metadata": {
        "id": "8tYPLXTTk9O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Apply the log transformation to the 'price' column in the training data\n",
        "train_df['log_price'] = np.log1p(train_df['price'])\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "MFX5FW33lEoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"log_price\"].describe()"
      ],
      "metadata": {
        "id": "a0guS_C7nojs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "sns.histplot(train_df['log_price'], bins=50, kde=True, ax=axes[0])\n",
        "axes[0].set_title('Distribution of Log-Transformed Prices (Histogram)')\n",
        "axes[0].set_xlabel('Log(Price)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "sns.boxplot(x=train_df['log_price'], ax=axes[1])\n",
        "axes[1].set_title('Distribution of Log-Transformed Prices (Box Plot)')\n",
        "axes[1].set_xlabel('Log(Price)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bs7yReKnnwYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "# Get 5 random samples to inspect\n",
        "sample_indices = random.sample(range(len(train_df)), 5)\n",
        "print(\"--- Checking for Punctuation and Special Characters ---\")\n",
        "for i in sample_indices:\n",
        "    text = train_df['catalog_content'][i]\n",
        "    # Use a regular expression to find all punctuation characters\n",
        "    punctuation_found = re.findall(f'[{re.escape(string.punctuation)}]', text)\n",
        "    print(f\"Sample {i}: Punctuation found: {set(punctuation_found)}\")"
      ],
      "metadata": {
        "id": "0IZ2P94dn4TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for \"Item Name:\", \"Value:\", \"Unit:\" patterns\n",
        "print(\"\\n--- Checking for Data Labels ---\")\n",
        "print(f\"Contains 'Item Name:' pattern: {train_df['catalog_content'].str.contains('Item Name:', na=False).sum()}\")\n",
        "print(f\"Contains 'Value:' pattern: {train_df['catalog_content'].str.contains('Value:', na=False).sum()}\")\n",
        "print(f\"Contains 'Unit:' pattern: {train_df['catalog_content'].str.contains('Unit:', na=False).sum()}\")"
      ],
      "metadata": {
        "id": "S4BtiPDOHPk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for HTML tags\n",
        "print(\"\\n--- Checking for HTML Tags ---\")\n",
        "html_tags_present = train_df['catalog_content'].str.contains('<.*?>', na=False).sum()\n",
        "print(f\"HTML tags are present: {html_tags_present}\")\n",
        "\n",
        "# Check for URLs\n",
        "print(\"\\n--- Checking for URLs ---\")\n",
        "urls_present = train_df['catalog_content'].str.contains('http[s]?://\\S+|www\\.\\S+', na=False).sum()\n",
        "print(f\"URLs are present: {urls_present}\")"
      ],
      "metadata": {
        "id": "51IZHZMsHhH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text_final(text):\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # 1. Handle common punctuation and symbols first\n",
        "    text = re.sub(r'\\'', '', text)  # Remove apostrophes\n",
        "\n",
        "    # Remove unwanted patterns\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'http[s]?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub(r'<.*?>+', '', text)\n",
        "\n",
        "    # Remove specific labels or prefixes\n",
        "    text = re.sub(r'(item name:|value:|unit:|bullet point:\\s*\\d+|bullet point)', '', text)\n",
        "\n",
        "    # Replace newlines and hyphens with a space\n",
        "    text = re.sub(r'[\\n\\-]', ' ', text)\n",
        "\n",
        "    # Remove all unwanted punctuation except '.' in numbers.\n",
        "    # This regex removes everything that is NOT a lowercase letter, a number, a space, or a decimal point.\n",
        "    text = re.sub(r'[^a-z0-9\\s\\.]', ' ', text)\n",
        "\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "oMr9Rz2CHvlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Assume train_df and test_df are loaded and clean_text_final_fixed is defined\n",
        "train_df['clean_catalog_content'] = train_df['catalog_content'].apply(clean_text_final)\n",
        "test_df['clean_catalog_content'] = test_df['catalog_content'].apply(clean_text_final)\n",
        "\n",
        "# Find samples with numbers to check if the decimal point is handled\n",
        "samples_with_decimals = train_df[train_df['catalog_content'].str.contains(r'\\d+\\.\\d+', na=False, regex=True)].index.tolist()\n",
        "\n",
        "if samples_with_decimals:\n",
        "    random_index = random.choice(samples_with_decimals)\n",
        "    original_text = train_df.loc[random_index, 'catalog_content']\n",
        "    cleaned_text = train_df.loc[random_index, 'clean_catalog_content']\n",
        "\n",
        "    print(f\"--- Checking a random sample with a decimal (Index: {random_index}) ---\")\n",
        "    print(\"Original Text:\", original_text)\n",
        "    print(\"Cleaned Text:\", cleaned_text)\n",
        "else:\n",
        "    print(\"No samples with decimal numbers found for this check.\")"
      ],
      "metadata": {
        "id": "32gkydwrQ_tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "id": "5SsSuuz9K9jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.columns"
      ],
      "metadata": {
        "id": "D1-wBa7cOMcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import random\n",
        "\n",
        "# Choose a random sample from the dataset\n",
        "random_index = random.randint(0, len(train_df) - 1)\n",
        "sample_text = train_df['catalog_content'][random_index]\n",
        "cleaned_text = clean_text_final(sample_text)\n",
        "\n",
        "print(f\"--- Checking a random sample (Index: {random_index}) ---\")\n",
        "print(\"Original Text:\", sample_text)\n",
        "print(\"Cleaned Text:\", cleaned_text)\n",
        "\n",
        "# Check if any punctuation remains in the cleaned text\n",
        "remaining_punctuation = set(cleaned_text).intersection(set(string.punctuation))\n",
        "print(f\"\\nRemaining punctuation in cleaned text: {remaining_punctuation}\")"
      ],
      "metadata": {
        "id": "p2e3jG5dOOnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "nolgkIStPAbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for the model\n",
        "X_train_text = train_df['clean_catalog_content'].fillna('')\n",
        "X_test_text = test_df['clean_catalog_content'].fillna('')\n",
        "y_train_log = train_df['log_price']"
      ],
      "metadata": {
        "id": "2WbMVnepXduH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=15000,\n",
        "    stop_words='english',\n",
        ")"
      ],
      "metadata": {
        "id": "_TJs-d6cXnDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)"
      ],
      "metadata": {
        "id": "eru9ceCAXqtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_tfidf, y_train_log)"
      ],
      "metadata": {
        "id": "OpCvrugZXyPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions and inverse transform them\n",
        "predictions_log = model.predict(X_test_tfidf)\n",
        "final_predictions = np.expm1(predictions_log)\n",
        "final_predictions[final_predictions < 0] = 0.01"
      ],
      "metadata": {
        "id": "wYFAr1QWYCJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame({\n",
        "    'sample_id': test_df['sample_id'],\n",
        "    'price': final_predictions\n",
        "})\n",
        "submission_df.to_csv('test_out_improved_text.csv', index=False)\n",
        "print(\"New submission file created with improved text features!\")"
      ],
      "metadata": {
        "id": "A--ooJTWYfWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming train_df has 'clean_catalog_content' and 'log_price' columns\n",
        "X_train_full = train_df['clean_catalog_content']\n",
        "y_train_log_full = train_df['log_price']\n",
        "\n",
        "# Split the data (80% for training, 20% for validation)\n",
        "X_train_subset, X_val, y_train_log_subset, y_val_log = train_test_split(\n",
        "    X_train_full,\n",
        "    y_train_log_full,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"New Training set size: {len(X_train_subset)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")"
      ],
      "metadata": {
        "id": "zI33c5ceZAPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create TF-IDF features based on the new subsets\n",
        "tfidf_vectorizer_val = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=15000,\n",
        "    stop_words='english',\n",
        ")\n",
        "\n",
        "X_train_subset_tfidf = tfidf_vectorizer_val.fit_transform(X_train_subset)\n",
        "X_val_tfidf = tfidf_vectorizer_val.transform(X_val)\n",
        "\n",
        "# Train the model\n",
        "model_val = LinearRegression()\n",
        "model_val.fit(X_train_subset_tfidf, y_train_log_subset)\n",
        "\n",
        "# Make predictions on the validation set and inverse transform\n",
        "predictions_val_log = model_val.predict(X_val_tfidf)\n",
        "predictions_val = np.expm1(predictions_val_log)\n",
        "predictions_val[predictions_val < 0] = 0.01\n",
        "\n",
        "# Inverse transform the actual prices for comparison\n",
        "y_val = np.expm1(y_val_log)"
      ],
      "metadata": {
        "id": "3ObD4-5-a786"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smape_score(y_true, y_pred):\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    smape = np.mean(np.abs(y_pred - y_true) / denominator) * 100\n",
        "    return smape\n",
        "\n",
        "smape = smape_score(y_val, predictions_val)\n",
        "print(f\"Your model's SMAPE score on the validation set is: {smape:.2f}%\")"
      ],
      "metadata": {
        "id": "Nm5b5rMtbA-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the preprocessed training data\n",
        "train_df.to_csv('train_preprocessed.csv', index=False)\n",
        "\n",
        "# Save the preprocessed test data\n",
        "test_df.to_csv('test_preprocessed.csv', index=False)\n",
        "\n",
        "print(\"Preprocessed DataFrames saved as CSVs!\")"
      ],
      "metadata": {
        "id": "D9fhY0ugbcCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the preprocessed dataframes\n",
        "train_df = pd.read_csv('train_preprocessed.csv')\n",
        "test_df = pd.read_csv('test_preprocessed.csv')\n",
        "\n",
        "# Verify the columns are correct\n",
        "print(\"Training DataFrame columns:\", train_df.columns)\n",
        "print(\"Test DataFrame columns:\", test_df.columns)\n",
        "\n",
        "# Check the first few rows to ensure data is loaded correctly\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "id": "seIW24Eo0TzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18a8b40-1d66-4ad9-8f09-df4edd4b1f7b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DataFrame columns: Index(['sample_id', 'catalog_content', 'image_link', 'price', 'word_count',\n",
            "       'log_price', 'clean_catalog_content'],\n",
            "      dtype='object')\n",
            "Test DataFrame columns: Index(['sample_id', 'catalog_content', 'image_link', 'clean_catalog_content'], dtype='object')\n",
            "   sample_id                                    catalog_content  \\\n",
            "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
            "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
            "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
            "3      55858  Item Name: Judee’s Blue Cheese Powder 11.25 oz...   \n",
            "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
            "\n",
            "                                          image_link  price  word_count  \\\n",
            "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89          18   \n",
            "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12          80   \n",
            "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97          59   \n",
            "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34         211   \n",
            "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49          28   \n",
            "\n",
            "   log_price                              clean_catalog_content  \n",
            "0   1.773256  la victoria green taco sauce mild 12 ounce pac...  \n",
            "1   2.647592  salerno cookies the original butter cookies 8 ...  \n",
            "2   1.088562  bear creek hearty soup bowl creamy chicken wit...  \n",
            "3   3.444895  judee s blue cheese powder 11.25 oz gluten fre...  \n",
            "4   4.211979  kedem sherry cooking wine 12.7 ounce 12 per ca...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruKQ9PMACAus",
        "outputId": "c4c872bc-5634-4a04-e010-e5b877c8905c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_k5HBH4C_UN",
        "outputId": "7675419c-e44a-4999-a637-f409c64b6965"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "base_resources_path = 'student_resource'\n",
        "src_path = os.path.join('/content', base_resources_path, 'src')\n",
        "sys.path.append(src_path)\n",
        "#/content/student_resource/src/utils.py\n",
        "from utils import download_images"
      ],
      "metadata": {
        "id": "pmAd7Ey2DRBI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = os.path.join('/content', 'product_images')\n",
        "os.makedirs(images_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "j9bggqYWDlby"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading training images...\")\n",
        "download_images(train_df['image_link'], images_dir)\n",
        "\n",
        "# Corrected code: Pass the 'image_link' column from the DataFrame\n",
        "print(\"Downloading test images...\")\n",
        "download_images(test_df['image_link'], images_dir)\n",
        "\n",
        "print(\"Image download complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLsQbp-vE5Sj",
        "outputId": "97bc6402-ca7b-4baa-ae55-3e05f17c4d9a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████▏    | 38452/75000 [00:03<00:03, 11248.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Not able to download - https://m.media-amazon.com/images/I/51mjZYDYjyL.jpg\n",
            "HTTP Error 404: Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75000/75000 [03:16<00:00, 382.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading test images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 41937/75000 [03:25<01:55, 286.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Not able to download - https://m.media-amazon.com/images/I/813CjSgHj0S.jpg\n",
            "HTTP Error 404: Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75000/75000 [06:06<00:00, 204.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image download complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set the device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load a pre-trained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Remove the final classification layer\n",
        "# The model will now output features, not class probabilities\n",
        "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "\n",
        "# Move the model to the GPU\n",
        "model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "print(\"ResNet50 model loaded and configured for feature extraction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-74S9TYAFEhK",
        "outputId": "765af933-6c1e-476f-b08b-f8c89f8ace84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 176MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet50 model loaded and configured for feature extraction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated code for feature extraction with batches and a custom collate function\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# A simple custom dataset class to handle image loading\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, os.path.basename(img_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Skipping image {img_path}. Error: {e}\")\n",
        "            return None, None\n",
        "\n",
        "# Define the custom collate function\n",
        "def custom_collate_fn(batch):\n",
        "    # Filter out None values\n",
        "    batch = list(filter(lambda x: x[0] is not None, batch))\n",
        "    if not batch:  # Check if the batch is empty after filtering\n",
        "        return None, None\n",
        "\n",
        "    images, image_ids = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    return images, image_ids\n",
        "\n",
        "# Define the image transformations\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Get all image paths\n",
        "image_dir = '/content/product_images'\n",
        "all_image_paths = glob.glob(os.path.join(image_dir, '*.jpg'))\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "batch_size = 32\n",
        "image_dataset = ImageDataset(all_image_paths, transform=preprocess)\n",
        "# Pass the custom collate function to the DataLoader\n",
        "image_dataloader = DataLoader(\n",
        "    image_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=custom_collate_fn\n",
        ")\n",
        "\n",
        "# Dictionary to store features\n",
        "all_image_features = {}\n",
        "\n",
        "# Extract features in batches\n",
        "print(\"Extracting features from images in batches...\")\n",
        "for images, image_ids in tqdm(image_dataloader, desc=\"Extracting features\"):\n",
        "    if images is None:  # Check for empty batches\n",
        "        continue\n",
        "    images = images.to(device)\n",
        "    with torch.no_grad():\n",
        "        features = model(images)\n",
        "\n",
        "    for i, img_id in enumerate(image_ids):\n",
        "        feature_vector = features[i].squeeze().cpu().numpy()\n",
        "        all_image_features[img_id] = feature_vector\n",
        "\n",
        "print(\"Feature extraction complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTrGQ_i3SDBB",
        "outputId": "5dd7c3d5-62c5-4308-d3fa-7304769a243e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from images in batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  14%|█▎        | 596/4394 [12:24<1:18:11,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/81z0a0BAO1L.jpg. Error: image file is truncated (19 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  22%|██▏       | 959/4394 [19:42<55:12,  1.04it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/71Mj291sDML.jpg. Error: image file is truncated (49 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  42%|████▏     | 1835/4394 [37:49<38:45,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/71dCty0zu8L.jpg. Error: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  42%|████▏     | 1851/4394 [38:11<50:56,  1.20s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/714E9M0xUZL.jpg. Error: image file is truncated (86 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  48%|████▊     | 2097/4394 [43:20<47:38,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/91TTiKjv+dL.jpg. Error: image file is truncated (17 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  48%|████▊     | 2110/4394 [43:35<39:26,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/71NHAiyjf6L.jpg. Error: image file is truncated (41 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  49%|████▉     | 2166/4394 [44:45<45:17,  1.22s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/91JlVlzhfaL.jpg. Error: image file is truncated (6 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  50%|████▉     | 2184/4394 [45:06<32:59,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/81eloOXKWYL.jpg. Error: image file is truncated (19 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  50%|█████     | 2198/4394 [45:24<40:57,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/81ileIhPdUL.jpg. Error: image file is truncated (6 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  53%|█████▎    | 2314/4394 [47:50<35:48,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/71qIYdDlKPL.jpg. Error: image file is truncated (6 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  56%|█████▌    | 2446/4394 [50:34<44:32,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/81QKTeB00bL.jpg. Error: image file is truncated (77 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  58%|█████▊    | 2560/4394 [53:00<42:07,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/81NyMMyJnJL.jpg. Error: image file is truncated (6 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  59%|█████▉    | 2604/4394 [53:54<27:51,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/81MdGhWTWLL.jpg. Error: image file is truncated (0 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  79%|███████▉  | 3473/4394 [1:12:11<20:31,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/813WLBmphVL.jpg. Error: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  80%|███████▉  | 3496/4394 [1:12:39<20:14,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/81cJHIW1UaL.jpg. Error: image file is truncated (28 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  81%|████████▏ | 3575/4394 [1:14:21<18:28,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/811mqH4cLpL.jpg. Error: image file is truncated (19 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  84%|████████▎ | 3677/4394 [1:16:26<11:39,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/91ppIA4KihL.jpg. Error: image file is truncated (43 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  86%|████████▌ | 3757/4394 [1:18:07<12:38,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/619o1M1ShXL.jpg. Error: image file is truncated (23 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  90%|█████████ | 3958/4394 [1:22:22<10:03,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/71g-yjYfvdL.jpg. Error: image file is truncated (2 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  91%|█████████▏| 4017/4394 [1:23:36<07:21,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/71ZCayr9PjL.jpg. Error: image file is truncated (4 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  93%|█████████▎| 4103/4394 [1:25:22<04:24,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping image /content/product_images/71nx2TuSR4L.jpg. Error: image file is truncated (3 bytes not processed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 4394/4394 [1:31:25<00:00,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming your dictionary is named all_image_features\n",
        "# Save the dictionary to a file in your Colab environment\n",
        "np.save('all_image_features.npy', all_image_features)\n",
        "\n",
        "print(\"Dictionary saved successfully to all_image_features.npy!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToVgXIkHTCoU",
        "outputId": "d4dbd403-5221-4328-e3dd-e654189fb364"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary saved successfully to all_image_features.npy!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the dictionary from the saved file\n",
        "all_image_features = np.load('all_image_features.npy', allow_pickle=True).item()\n",
        "\n",
        "print(\"Dictionary loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwfMqLf4BrDb",
        "outputId": "9e881821-4faf-4071-b30a-381c7fa8ef56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load your preprocessed dataframes\n",
        "train_df = pd.read_csv('train_preprocessed.csv')\n",
        "test_df = pd.read_csv('test_preprocessed.csv')\n",
        "\n",
        "# Load the image features dictionary\n",
        "# Make sure the file path is correct (e.g., in your Google Drive)\n",
        "all_image_features = np.load('all_image_features.npy', allow_pickle=True).item()"
      ],
      "metadata": {
        "id": "M1niMH4WTo1S"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image features dictionary to a DataFrame for easier merging\n",
        "image_features_df = pd.DataFrame.from_dict(all_image_features, orient='index')\n",
        "image_features_df.index.name = 'filename'\n",
        "\n",
        "# Extract the filename (unique ID) from the original image_link\n",
        "train_df['filename'] = train_df['image_link'].apply(lambda x: x.split('/')[-1])\n",
        "test_df['filename'] = test_df['image_link'].apply(lambda x: x.split('/')[-1])\n",
        "\n",
        "# Merge the image features into the original dataframes\n",
        "train_df = train_df.merge(image_features_df, on='filename', how='left')\n",
        "test_df = test_df.merge(image_features_df, on='filename', how='left')\n",
        "\n",
        "# The merge might have created NaNs for products without a downloaded image.\n",
        "# We'll fill these missing values with zeros.\n",
        "train_df = train_df.fillna(0)\n",
        "test_df = test_df.fillna(0)\n",
        "\n",
        "print(\"Text and image features have been combined.\")"
      ],
      "metadata": {
        "id": "OjOTlNAL96h-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b862c648-5df8-43a6-a196-b12e3f999862"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1472746195.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert the image features dictionary to a DataFrame for easier merging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_features_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_image_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimage_features_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'filename'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Extract the filename (unique ID) from the original image_link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZEaXI70gam0W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}