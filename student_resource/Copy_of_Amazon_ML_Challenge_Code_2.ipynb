{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LvQntpS3eWfD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_path=\"/Users/sanskarparab/Downloads/Amazon ML/all_image_features.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "h_Cz0yfghFzh"
   },
   "outputs": [],
   "source": [
    "all_image_features = np.load(image_feature_path, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OKUURllvhO46"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_preprocessed.csv')\n",
    "test_df = pd.read_csv('test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k9gIWZLAhe-x"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6qWf2RJPhxwG"
   },
   "outputs": [],
   "source": [
    "image_filenames = list(all_image_features.keys())\n",
    "image_feature_vectors = np.array(list(all_image_features.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1cmLPNSlg7o",
    "outputId": "a1a1ff41-67e3-4814-8d35-6fcb2157f655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image feature vectors: (140564, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of image feature vectors: {image_feature_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hx96SgClnt-",
    "outputId": "4ea23a31-5d2f-4413-d07c-75e9be491378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image filenames: 140564\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of image filenames: {len(image_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6IraTEG-itzN"
   },
   "outputs": [],
   "source": [
    "image_features_df = pd.DataFrame(image_feature_vectors, index=image_filenames)\n",
    "image_features_df.index.name = 'filename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "s5CBVXljmgQ-",
    "outputId": "170cfca4-d6b2-4c4d-85a0-3216be8633ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81HBeypM9OL.jpg</th>\n",
       "      <td>0.345448</td>\n",
       "      <td>0.456050</td>\n",
       "      <td>0.988337</td>\n",
       "      <td>0.188612</td>\n",
       "      <td>1.000779</td>\n",
       "      <td>0.882697</td>\n",
       "      <td>0.284630</td>\n",
       "      <td>0.178169</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>0.174903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343704</td>\n",
       "      <td>0.365218</td>\n",
       "      <td>0.503408</td>\n",
       "      <td>0.772206</td>\n",
       "      <td>0.450264</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>0.786766</td>\n",
       "      <td>0.198780</td>\n",
       "      <td>0.568652</td>\n",
       "      <td>0.551720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810csPIv4ML.jpg</th>\n",
       "      <td>0.454637</td>\n",
       "      <td>2.012997</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.197275</td>\n",
       "      <td>1.565557</td>\n",
       "      <td>0.391016</td>\n",
       "      <td>0.379122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.899287</td>\n",
       "      <td>0.111666</td>\n",
       "      <td>...</td>\n",
       "      <td>1.132990</td>\n",
       "      <td>0.085762</td>\n",
       "      <td>0.614638</td>\n",
       "      <td>0.066585</td>\n",
       "      <td>0.421780</td>\n",
       "      <td>0.064931</td>\n",
       "      <td>0.826992</td>\n",
       "      <td>0.535516</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.137041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6101ttR-AYL.jpg</th>\n",
       "      <td>0.484811</td>\n",
       "      <td>1.458574</td>\n",
       "      <td>0.069766</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.866891</td>\n",
       "      <td>0.236085</td>\n",
       "      <td>0.923649</td>\n",
       "      <td>0.148647</td>\n",
       "      <td>1.097531</td>\n",
       "      <td>0.172585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954126</td>\n",
       "      <td>0.139147</td>\n",
       "      <td>0.311189</td>\n",
       "      <td>0.424142</td>\n",
       "      <td>0.037661</td>\n",
       "      <td>0.162902</td>\n",
       "      <td>0.316644</td>\n",
       "      <td>0.052916</td>\n",
       "      <td>0.537284</td>\n",
       "      <td>1.053032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61NBIHn2h2L.jpg</th>\n",
       "      <td>0.073060</td>\n",
       "      <td>2.343555</td>\n",
       "      <td>0.076419</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.797889</td>\n",
       "      <td>0.610318</td>\n",
       "      <td>0.472866</td>\n",
       "      <td>0.150804</td>\n",
       "      <td>0.255709</td>\n",
       "      <td>0.307382</td>\n",
       "      <td>...</td>\n",
       "      <td>1.641964</td>\n",
       "      <td>0.236993</td>\n",
       "      <td>0.588280</td>\n",
       "      <td>0.240443</td>\n",
       "      <td>0.023469</td>\n",
       "      <td>0.123733</td>\n",
       "      <td>0.721824</td>\n",
       "      <td>0.131618</td>\n",
       "      <td>0.071839</td>\n",
       "      <td>0.093984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71zXpZMpAXL.jpg</th>\n",
       "      <td>0.718636</td>\n",
       "      <td>0.452312</td>\n",
       "      <td>0.414025</td>\n",
       "      <td>0.102791</td>\n",
       "      <td>0.555732</td>\n",
       "      <td>1.556470</td>\n",
       "      <td>0.295050</td>\n",
       "      <td>0.192128</td>\n",
       "      <td>0.072017</td>\n",
       "      <td>0.022006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230032</td>\n",
       "      <td>0.054227</td>\n",
       "      <td>0.802946</td>\n",
       "      <td>0.030594</td>\n",
       "      <td>0.414451</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>0.181495</td>\n",
       "      <td>0.134494</td>\n",
       "      <td>0.914550</td>\n",
       "      <td>0.180633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5     \\\n",
       "filename                                                                      \n",
       "81HBeypM9OL.jpg  0.345448  0.456050  0.988337  0.188612  1.000779  0.882697   \n",
       "810csPIv4ML.jpg  0.454637  2.012997  0.054166  0.197275  1.565557  0.391016   \n",
       "6101ttR-AYL.jpg  0.484811  1.458574  0.069766  0.000352  0.866891  0.236085   \n",
       "61NBIHn2h2L.jpg  0.073060  2.343555  0.076419  0.007601  0.797889  0.610318   \n",
       "71zXpZMpAXL.jpg  0.718636  0.452312  0.414025  0.102791  0.555732  1.556470   \n",
       "\n",
       "                     6         7         8         9     ...      2038  \\\n",
       "filename                                                 ...             \n",
       "81HBeypM9OL.jpg  0.284630  0.178169  0.913208  0.174903  ...  0.343704   \n",
       "810csPIv4ML.jpg  0.379122  0.000000  0.899287  0.111666  ...  1.132990   \n",
       "6101ttR-AYL.jpg  0.923649  0.148647  1.097531  0.172585  ...  0.954126   \n",
       "61NBIHn2h2L.jpg  0.472866  0.150804  0.255709  0.307382  ...  1.641964   \n",
       "71zXpZMpAXL.jpg  0.295050  0.192128  0.072017  0.022006  ...  0.230032   \n",
       "\n",
       "                     2039      2040      2041      2042      2043      2044  \\\n",
       "filename                                                                      \n",
       "81HBeypM9OL.jpg  0.365218  0.503408  0.772206  0.450264  0.022612  0.786766   \n",
       "810csPIv4ML.jpg  0.085762  0.614638  0.066585  0.421780  0.064931  0.826992   \n",
       "6101ttR-AYL.jpg  0.139147  0.311189  0.424142  0.037661  0.162902  0.316644   \n",
       "61NBIHn2h2L.jpg  0.236993  0.588280  0.240443  0.023469  0.123733  0.721824   \n",
       "71zXpZMpAXL.jpg  0.054227  0.802946  0.030594  0.414451  0.012609  0.181495   \n",
       "\n",
       "                     2045      2046      2047  \n",
       "filename                                       \n",
       "81HBeypM9OL.jpg  0.198780  0.568652  0.551720  \n",
       "810csPIv4ML.jpg  0.535516  0.021000  0.137041  \n",
       "6101ttR-AYL.jpg  0.052916  0.537284  1.053032  \n",
       "61NBIHn2h2L.jpg  0.131618  0.071839  0.093984  \n",
       "71zXpZMpAXL.jpg  0.134494  0.914550  0.180633  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-0uLyUwmqAy",
    "outputId": "dbf3f071-7ea8-411a-c028-48d921a651f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnuSKvXUmtol",
    "outputId": "d0174203-9d98-4d19-e470-ae64c4b78e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d3VGBazHixjp"
   },
   "outputs": [],
   "source": [
    "all_df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeKVlcm9mw8c",
    "outputId": "695ec582-73cf-4f53-d9e3-b24f3112c0d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLIVwRvci1Vb",
    "outputId": "81cf7e0c-7be9-41de-ea3a-d92bf817b058"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140564, 2048)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9lytWH6nCM1",
    "outputId": "a1892f35-8f88-49ab-bb40-4055a95bb9d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['price'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FS0pC_a0i-9i"
   },
   "outputs": [],
   "source": [
    "all_df['filename'] = all_df['image_link'].apply(lambda x: os.path.basename(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "w5Un7WzUj5dO"
   },
   "outputs": [],
   "source": [
    "final_all_df = all_df.merge(image_features_df, on='filename', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pxj438kBpZW7",
    "outputId": "c8298777-18ac-4820-d61a-3f52c5c001f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Columns: 2056 entries, sample_id to 2047\n",
      "dtypes: float32(2048), float64(3), int64(1), object(4)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "final_all_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OGtvVydpipF",
    "outputId": "9f70ef2d-be5a-46ab-a1d0-619f2889bfb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 2056)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WPBbli3Qpree"
   },
   "outputs": [],
   "source": [
    "image_feature_cols = [col for col in final_all_df.columns if isinstance(col, (int, float))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7pFcPp9pvT0",
    "outputId": "5cf44a85-ec92-46b4-8f43-a805e2b7e350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Image Feature Columns (First 5) ---\n",
      "[0, 1, 2, 3, 4]\n",
      "\n",
      "--- Non-Image Feature Columns ---\n",
      "['sample_id', 'catalog_content', 'image_link', 'price', 'word_count', 'log_price', 'clean_catalog_content', 'filename']\n"
     ]
    }
   ],
   "source": [
    "non_image_feature_cols = [col for col in final_all_df.columns if not isinstance(col, (int, float))]\n",
    "\n",
    "# Print the list of image feature columns (a small sample)\n",
    "print(\"--- Image Feature Columns (First 5) ---\")\n",
    "print(image_feature_cols[:5])\n",
    "\n",
    "# Print the list of non-image feature columns (all of them)\n",
    "print(\"\\n--- Non-Image Feature Columns ---\")\n",
    "print(non_image_feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "u8zWn91TqKKb"
   },
   "outputs": [],
   "source": [
    "final_all_df[image_feature_cols] = final_all_df[image_feature_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2VuFeGdqTZ1",
    "outputId": "e3a25ed1-1f45-4b1b-98a7-322f31c13b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training set shape: (75000, 2056)\n",
      "Final test set shape: (75000, 2056)\n"
     ]
    }
   ],
   "source": [
    "test_ids = test_df['sample_id'].tolist()\n",
    "\n",
    "# Split the data back into final train and test sets\n",
    "train_df_final = final_all_df.loc[~final_all_df['sample_id'].isin(test_ids)].reset_index(drop=True)\n",
    "test_df_final = final_all_df.loc[final_all_df['sample_id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Final training set shape: {train_df_final.shape}\")\n",
    "print(f\"Final test set shape: {test_df_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "16JXMpPxkdhF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vz1RKmesrEKi"
   },
   "outputs": [],
   "source": [
    "X_all_features = train_df_final.drop(['price', 'log_price', 'sample_id', 'image_link', 'word_count', 'filename'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZG_vznRErLD1"
   },
   "outputs": [],
   "source": [
    "y_all_log = train_df_final['log_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "uzh-NiQG6bzd"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ptaaO-Q3rPsy"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_subset, X_val, y_train_log_subset, y_val_log = train_test_split(\n",
    "    X_all_features,\n",
    "    y_all_log,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvgW5xzj88oM",
    "outputId": "63e7dae0-1afd-40ee-c5bc-41f8f23e159c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer and feature matrices created successfully!\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=10000, stop_words='english')\n",
    "\n",
    "# The fit_transform is done on the training subset\n",
    "X_train_subset_text_tfidf = vectorizer.fit_transform(X_train_subset['clean_catalog_content'])\n",
    "\n",
    "# The transform is done on the validation set, using the same vectorizer\n",
    "X_val_text_tfidf = vectorizer.transform(X_val['clean_catalog_content'])\n",
    "\n",
    "# --- Get image features for training and validation ---\n",
    "# Identify the image feature columns\n",
    "image_feature_cols = [col for col in X_train_subset.columns if isinstance(col, (int, float))]\n",
    "X_train_subset_image = X_train_subset[image_feature_cols].values\n",
    "X_val_image = X_val[image_feature_cols].values\n",
    "\n",
    "print(\"Vectorizer and feature matrices created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.5-py3-none-macosx_12_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from xgboost) (1.15.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "XERhTe7n6l9p"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "1GtiBdxA9dWh"
   },
   "outputs": [],
   "source": [
    "def smape_score(y_true, y_pred):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    smape = np.mean(np.abs(y_pred - y_true) / denominator) * 100\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1rABHGTBeU8",
    "outputId": "812dbd89-c8f0-4cd4-fd76-a02419e4a3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model on Text features...\n",
      "Training XGBoost model on Image features...\n",
      "Your combined XGBoost model's SMAPE score on the validation set is: 57.56%\n"
     ]
    }
   ],
   "source": [
    "# Import XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your data and variables are correctly prepared:\n",
    "# X_train_subset_text_tfidf, X_val_text_tfidf, y_train_log_subset, y_val_log\n",
    "# X_train_subset_image, X_val_image\n",
    "\n",
    "# -----------------\n",
    "# FINAL MODEL TRAINING\n",
    "# -----------------\n",
    "\n",
    "# Train a model on TEXT features only\n",
    "print(\"Training XGBoost model on Text features...\")\n",
    "text_model = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=7,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "text_model.fit(X_train_subset_text_tfidf, y_train_log_subset,\n",
    "               eval_set=[(X_val_text_tfidf, y_val_log)],\n",
    "               verbose=False)\n",
    "text_preds_val_log = text_model.predict(X_val_text_tfidf)\n",
    "\n",
    "# Train a separate model on IMAGE features only\n",
    "print(\"Training XGBoost model on Image features...\")\n",
    "image_model = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=7,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "image_model.fit(X_train_subset_image, y_train_log_subset,\n",
    "                eval_set=[(X_val_image, y_val_log)],\n",
    "                verbose=False)\n",
    "image_preds_val_log = image_model.predict(X_val_image)\n",
    "\n",
    "# Combine the predictions\n",
    "combined_preds_val_log = (text_preds_val_log * 0.5) + (image_preds_val_log * 0.5)\n",
    "\n",
    "# Inverse transform to get the final prices\n",
    "combined_preds_val = np.expm1(combined_preds_val_log)\n",
    "combined_preds_val[combined_preds_val < 0] = 0.01\n",
    "\n",
    "# Calculate SMAPE\n",
    "smape = smape_score(np.expm1(y_val_log), combined_preds_val)\n",
    "print(f\"Your combined XGBoost model's SMAPE score on the validation set is: {smape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "rewlV7Tn64uR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final submission file created successfully as 'final_submission_final.csv'!\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# âœ… PREDICT ON TEST DATA\n",
    "# --------------------------\n",
    "\n",
    "# 1ï¸âƒ£ Vectorize text in test data using the same vectorizer\n",
    "X_test_text_tfidf = vectorizer.transform(test_df_final['clean_catalog_content'])\n",
    "\n",
    "# 2ï¸âƒ£ Get image features for test data (same way as train)\n",
    "X_test_image = test_df_final[image_feature_cols].values\n",
    "\n",
    "# 3ï¸âƒ£ Predict log prices separately for text & image\n",
    "text_preds_test_log = text_model.predict(X_test_text_tfidf)\n",
    "image_preds_test_log = image_model.predict(X_test_image)\n",
    "\n",
    "# 4ï¸âƒ£ Combine them (you can tune these weights)\n",
    "final_predictions_log = (text_preds_test_log * 0.5) + (image_preds_test_log * 0.5)\n",
    "\n",
    "# 5ï¸âƒ£ Convert back from log scale to original prices\n",
    "final_predictions = np.expm1(final_predictions_log)\n",
    "final_predictions[final_predictions < 0] = 0.01  # Avoid negatives\n",
    "\n",
    "# 6ï¸âƒ£ Create the final submission CSV\n",
    "submission_df = pd.DataFrame({\n",
    "    'sample_id': test_df_final['sample_id'],\n",
    "    'price': final_predictions\n",
    "})\n",
    "submission_df.to_csv('final_submission_final.csv', index=False)\n",
    "\n",
    "print(\"âœ… Final submission file created successfully as 'final_submission_final.csv'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined training and validation features successfully!\n",
      "Training final XGBoost model on combined features...\n",
      "[0]\tvalidation_0-rmse:0.94739\n",
      "[200]\tvalidation_0-rmse:0.75481\n",
      "[400]\tvalidation_0-rmse:0.73562\n",
      "[600]\tvalidation_0-rmse:0.72616\n",
      "[800]\tvalidation_0-rmse:0.71974\n",
      "[1000]\tvalidation_0-rmse:0.71509\n",
      "[1200]\tvalidation_0-rmse:0.71121\n",
      "[1400]\tvalidation_0-rmse:0.70830\n",
      "[1600]\tvalidation_0-rmse:0.70567\n",
      "[1800]\tvalidation_0-rmse:0.70364\n",
      "[2000]\tvalidation_0-rmse:0.70201\n",
      "[2200]\tvalidation_0-rmse:0.70043\n",
      "[2400]\tvalidation_0-rmse:0.69904\n",
      "[2499]\tvalidation_0-rmse:0.69856\n",
      "âœ… SMAPE on validation set: 53.70%\n",
      "ðŸŽ¯ Final submission file saved as 'final_submission_final2.csv'!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# ---------------------------\n",
    "# Combine TEXT + IMAGE features\n",
    "# ---------------------------\n",
    "\n",
    "# Combine the TF-IDF (sparse) and image (dense) features\n",
    "X_train_combined = hstack([X_train_subset_text_tfidf, csr_matrix(X_train_subset_image)])\n",
    "X_val_combined = hstack([X_val_text_tfidf, csr_matrix(X_val_image)])\n",
    "\n",
    "print(\"Combined training and validation features successfully!\")\n",
    "\n",
    "# ---------------------------\n",
    "# Train XGBoost model\n",
    "# ---------------------------\n",
    "print(\"Training final XGBoost model on combined features...\")\n",
    "\n",
    "combined_model = XGBRegressor(\n",
    "    n_estimators=2500,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "combined_model.fit(\n",
    "    X_train_combined,\n",
    "    y_train_log_subset,\n",
    "    eval_set=[(X_val_combined, y_val_log)],\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Validation Predictions + SMAPE\n",
    "# ---------------------------\n",
    "preds_val_log = combined_model.predict(X_val_combined)\n",
    "preds_val = np.expm1(preds_val_log)\n",
    "preds_val[preds_val < 0] = 0.01\n",
    "\n",
    "# Compute SMAPE\n",
    "smape = smape_score(np.expm1(y_val_log), preds_val)\n",
    "print(f\"âœ… SMAPE on validation set: {smape:.2f}%\")\n",
    "\n",
    "# ---------------------------\n",
    "# Predict on TEST DATA\n",
    "# ---------------------------\n",
    "# Combine TF-IDF and image features for test set\n",
    "X_test_combined = hstack([X_test_text_tfidf, csr_matrix(X_test_image)])\n",
    "\n",
    "# Predict\n",
    "final_predictions_log = combined_model.predict(X_test_combined)\n",
    "final_predictions = np.expm1(final_predictions_log)\n",
    "final_predictions[final_predictions < 0] = 0.01\n",
    "\n",
    "# ---------------------------\n",
    "# Create Final Submission\n",
    "# ---------------------------\n",
    "submission_df = pd.DataFrame({\n",
    "    'sample_id': test_df_final['sample_id'],\n",
    "    'price': final_predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv('final_submission_final2.csv', index=False)\n",
    "print(\"ðŸŽ¯ Final submission file saved as 'final_submission_final2.csv'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
